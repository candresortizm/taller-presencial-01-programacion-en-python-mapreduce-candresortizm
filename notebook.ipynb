{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprtación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import fileinput\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de carga de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(input_directory):\n",
    "    dir_path = input_directory + \"/*.txt\"\n",
    "    filenames = glob.glob(dir_path)\n",
    "    sequence=[]\n",
    "\n",
    "    with fileinput.input(files=filenames) as file:\n",
    "        for line in file:\n",
    "            tupla =(fileinput.filename(), line)\n",
    "            sequence.append(tupla)\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para partir las líneas en palabras y devolverlo en una tupla con un 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(sequence):\n",
    "    new_sequence =[]\n",
    "    for _, text in sequence:\n",
    "        for word in text.split():\n",
    "            word = word.replace(\",\",\"\")\n",
    "            word = word.replace(\".\",\"\")\n",
    "            word =word.lower()\n",
    "            tupla = (word,1)\n",
    "            new_sequence.append(tupla)\n",
    "    return new_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenar la lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_and_sort(sequence):\n",
    "    sorted_sequence = sorted(sequence, key=lambda x: x[0])\n",
    "    return sorted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(sequence):\n",
    "    diccionario = {}\n",
    "    #for key,value in sequence:\n",
    "    #    if key not in diccionario.keys():\n",
    "    #        diccionario[key] = []\n",
    "    #    diccionario[key].append(value)\n",
    "    \n",
    "    new_sequence = []\n",
    "    #for key,value in diccionario.items():\n",
    "    #    tupla = (key, sum(value))\n",
    "    #    new_sequence.append(tupla)\n",
    "\n",
    "    for key,value in sequence:\n",
    "        if key not in diccionario.keys():\n",
    "            diccionario[key] = 0\n",
    "        diccionario[key] += value\n",
    "    \n",
    "    for key,value in diccionario.items():\n",
    "        tupla = (key, value)\n",
    "        new_sequence.append(tupla)\n",
    "    \n",
    "    return new_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ouptput_directory(output_directory):\n",
    "    if os.path.exists(output_directory):\n",
    "        raise FileExistsError(f\"The directory '{output_directory}' already exists.\")\n",
    "    os.makedirs(output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(output_directory, sequence):\n",
    "    with open(output_directory+ \"/part-00000\", \"w\") as file:\n",
    "        for key, value in sequence:\n",
    "            file.write(f\"{key}\\t{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_marker(output_directory):\n",
    "    with open(output_directory + \"/_SUCCESS\", \"w\") as file:\n",
    "        file.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(bi)', 1), ('a', 4), ('across', 3), ('actionable', 3), ('adapt', 1), ('address', 1), ('advantages', 1), ('agility', 1), ('aimed', 3), ('algorithms', 2), ('all', 1), ('along', 1), ('among', 1), ('an', 1), ('analysis', 4), ('analytics', 5), ('analyze', 2), ('and', 35), ('applied', 1), ('as', 4), ('at', 3), ('be', 1), ('become', 1), ('behaviors', 1), ('bi', 2), ('broad', 1), ('business', 7), ('businesses', 1), ('by', 3), ('can', 2), ('challenges', 1), ('changing', 1), ('cleaning', 1), ('collecting', 1), ('collection', 1), ('communication', 1), ('competitive', 2), ('complex', 3), ('computational', 3), ('computer', 1), ('conditions', 1), ('correlations', 2), ('crucial', 1), ('customer', 1), ('data', 19), ('data-driven', 2), ('datasets', 3), ('decision-making', 4), ('decisions', 3), ('deeper', 1), ('derive', 1), ('deriving', 1), ('development', 1), ('discovering', 1), ('discovery', 1), ('diverse', 1), ('domain-specific', 1), ('domains', 2), ('drive', 3), ('driving', 1), ('dynamic', 1), ('dynamics', 1), ('edge', 1), ('emerging', 1), ('employs', 1), ('empowers', 1), ('enables', 1), ('encompasses', 3), ('essential', 1), ('exponential', 1), ('extract', 1), ('extracting', 2), ('facilitates', 1), ('field', 1), ('finance', 3), ('for', 2), ('forecast', 1), ('fostering', 2), ('from', 6), ('future', 1), ('gain', 2), ('gaining', 1), ('generation', 1), ('growth', 1), ('harnessing', 2), ('has', 1), ('healthcare', 3), ('heavily', 1), ('hidden', 2), ('identify', 1), ('improvements', 1), ('in', 4), ('including', 4), ('increasingly', 1), ('industries', 2), ('information', 1), ('informed', 3), ('informing', 1), ('innovation', 3), ('insights', 6), ('intelligence', 3), ('interdisciplinary', 1), ('interpret', 1), ('interpretation', 2), ('into', 1), ('involves', 3), ('involving', 1), ('is', 2), ('it', 6), ('knowledge', 2), ('landscape', 1), ('languages', 1), ('learning', 2), ('leverage', 1), ('like', 1), ('machine', 2), ('make', 2), ('making', 1), ('market', 2), ('marketing', 1), ('mathematical', 1), ('mathematics', 1), ('meaningful', 2), ('methodologies', 2), ('methods', 1), ('mining', 2), ('mitigate', 2), ('modeling', 4), ('of', 9), ('offering', 1), ('often', 2), ('on', 1), ('operational', 1), ('operations', 1), ('opportunities', 1), ('optimization', 1), ('optimize', 3), ('or', 4), ('order', 1), ('organizations', 3), ('organizing', 1), ('others', 1), ('outcomes', 2), ('patterns', 6), ('performance', 1), ('planning', 1), ('play', 1), ('power', 1), ('practices', 1), ('predict', 1), ('predictive', 3), ('principles', 1), ('process', 1), ('processes', 6), ('programming', 1), ('purpose', 1), ('python', 1), ('r', 1), ('range', 1), ('raw', 2), ('real-world', 1), ('refers', 2), ('relies', 1), ('respective', 1), ('risks', 3), ('role', 1), ('science', 5), ('scientific', 1), ('scientists', 1), ('sets', 2), ('spans', 1), ('sql', 1), ('statistical', 3), ('statistics', 3), ('strategic', 2), ('strategies', 2), ('structured', 1), ('such', 2), ('support', 1), ('swiftly', 1), ('systematic', 2), ('systems', 1), ('techniques', 3), ('technologies', 2), ('technology', 1), ('that', 2), ('the', 8), ('their', 2), ('they', 1), ('this', 1), ('to', 16), (\"today's\", 1), ('tools', 3), ('transformation', 1), ('transforming', 1), ('trends', 4), ('typically', 2), ('ultimately', 1), ('uncover', 3), ('uncovering', 1), ('understanding', 1), ('unstructured', 1), ('utilized', 1), ('valuable', 1), ('various', 4), ('vast', 1), ('visualization', 2), ('well', 1), ('with', 2), ('within', 3)]\n"
     ]
    }
   ],
   "source": [
    "sequence = load_input(\"input\")\n",
    "sequence = mapper(sequence)\n",
    "sequence = shuffle_and_sort(sequence)\n",
    "sequence = reducer(sequence)\n",
    "print(sequence)\n",
    "create_ouptput_directory(\"output\")\n",
    "save_output(\"output\",sequence)\n",
    "create_marker(\"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
